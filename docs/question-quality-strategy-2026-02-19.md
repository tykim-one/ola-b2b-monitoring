# 채팅 품질 개선 전략: "좋은 질문" 프레임워크

> **작성일**: 2026-02-19  
> **분석 기간**: 2026-01-27 ~ 2026-02-19  
> **데이터**: 12,798건 / 8,858세션

---

## 0. 논의 쟁점 정리

팀 논의에서 나온 핵심 질문들:

| # | 쟁점 | 이 보고서에서의 답변 위치 |
|---|------|----------------------|
| 1 | "괜찮은 질문"이란? | §1 — 2축 프레임워크로 정의 |
| 2 | 우리가 답변을 잘 할 수 있는 질문인지? | §2 — 카테고리별 응답 성공률 데이터 |
| 3 | 질문 자체에 수준이 있는지? 판단 근거? | §1.2 — 질문 수준 평가 5가지 축 |
| 4 | 주식시장에서 좋은 질문의 평가 지표 | §1.3 — 도메인 특화 지표 7개 |
| 5 | 답변을 잘하는 질문 리스트 → 자체 평가 기준 | §3 — Golden Set 구축 전략 |
| 6 | 새 채팅 편입 판단 | §4 — 실시간 분류 파이프라인 |
| 7 | 종목명 진입 → 추천질문만 사용 | §5.1 — 유저 행동 데이터 분석 |
| 8 | 채팅수 많으면 답변 품질 저하 | §5.2 — 트래픽 vs 품질 상관 분석 |
| 9 | 같은 형식 + 다른 종목 = 다른 질문? | §5.3 — 템플릿 vs 인스턴스 구분 |
| 10 | 전체 질문 LLM 카테고라이징 → 인사이트 | §6 — 실행 계획 |

---

## 1. "좋은 질문"이란 무엇인가

### 1.1 2축 프레임워크: 답변가능성 × 질문수준

기존 논의에서 두 가지 관점이 나왔습니다:
- **우리가 답변을 잘 할 수 있는 질문인지?** → 시스템 역량 축
- **질문 자체에 수준이 있는지?** → 질문 품질 축

이 둘은 **독립적**입니다. 조합하면 4분면이 나옵니다:

```
                    답변가능성 높음
                         │
        ┌────────────────┼────────────────┐
        │   ★ SWEET SPOT │  GOLD MINE     │
        │  답변 잘 됨 +   │  좋은 질문인데  │
질문     │  질문도 좋음    │  우리가 못 답변  │
수준     │                │  → 역량 확장 대상│
높음 ────┼────────────────┼────────────────┤
        │   CASH COW     │  OUT OF SCOPE  │
        │  단순하지만     │  수준도 낮고     │
질문     │  답변 잘 됨    │  답변도 못 함    │
수준     │  → 안정적 유지  │  → 필터링 대상   │
낮음     └────────────────┼────────────────┘
                         │
                    답변가능성 낮음
```

**실제 데이터 매핑:**

| 분면 | 예시 | 건수 | 비율 |
|------|------|------|------|
| ★ **SWEET SPOT** | "삼성전자 최근 재무 지표와 주요 뉴스 분석" | ~8,300 | 65% |
| **CASH COW** | "삼성전자" (종목명만) → 종합분석 자동 제공 | ~2,700 | 21% |
| **GOLD MINE** | "SK하이닉스 재무 지표 + 투자 유의사항" → Type A 거절 | ~460 | 3.6% |
| **OUT OF SCOPE** | "개명", "자녀", "충전" | ~220 | 1.7% |
| 미분류 | 기타 | ~1,000 | 7.8% |

### 1.2 질문 수준(Quality) 평가 — 5가지 축

"질문 자체에 수준이 있는지"를 판단하는 근거:

| 축 | 설명 | 점수 기준 | 예시 (높음 → 낮음) |
|----|------|----------|------------------|
| **구체성** (Specificity) | 대상이 명확한가 | 종목코드 포함(3) > 종목명(2) > "주식"(1) > 없음(0) | "삼성전자(005930)" vs "반도체" vs "주식" |
| **의도 명확성** (Intent Clarity) | 뭘 원하는지 알 수 있나 | 명시적 요청(3) > 암시적(2) > 모호(1) > 불명(0) | "최근 3개월 매출 추이" vs "전망" vs "?" |
| **분석 깊이** (Analytical Depth) | 단순 조회 vs 분석 요청 | 복합 분석(3) > 단일 분석(2) > 조회(1) > 감탄(0) | "재무+뉴스+전망 종합" vs "현재가?" vs "ㅋㅋ" |
| **시간적 맥락** (Temporal Context) | 시점이 특정되어 있나 | 기간 명시(2) > 최근(1) > 없음(0) | "최근 3개월" vs "최근" vs (없음) |
| **비교 프레임** (Comparative Frame) | 비교 기준이 있나 | 구체적 비교(2) > 동종 비교(1) > 없음(0) | "SK하이닉스 vs 삼성전자 PER" vs "비슷한 종목" |

**종합 점수**: 0~13점 → **Tier 분류**

| Tier | 점수 | 라벨 | 비율(추정) |
|------|------|------|----------|
| S | 10~13 | 전문 분석 요청 | ~5% |
| A | 7~9 | 구체적 정보 요청 | ~25% |
| B | 4~6 | 일반 질문 | ~45% |
| C | 1~3 | 단순 입력 | ~20% |
| D | 0 | 의미 없는 입력 | ~5% |

### 1.3 주식시장 도메인 특화 "좋은 질문" 지표 7가지

| # | 지표 | 측정 방법 | 왜 중요한가 |
|---|------|----------|-----------|
| 1 | **종목 특정성** | 종목명/코드 포함 여부 | 특정 종목이 있어야 데이터 조회 가능 |
| 2 | **정보 유형 명시** | 주가/재무/뉴스/배당 등 키워드 | 어떤 데이터를 반환할지 결정 |
| 3 | **시간 범위** | 기간 표현 포함 여부 | "최근 3개월 실적" vs "실적" |
| 4 | **분석 관점** | 투자/기술적/펀더멘털 등 | 응답의 프레이밍 결정 |
| 5 | **비교 요소** | 다른 종목/시점/지표와 비교 | 부가가치 높은 분석 가능 |
| 6 | **실행 가능성** | 답변으로 행동할 수 있는지 | "매도 타이밍" vs "주식이란" |
| 7 | **데이터 기반성** | 객관적 데이터로 답변 가능한지 | "재무제표" vs "느낌" |

---

## 2. 카테고리별 응답 품질 현황 (팩트)

### 2.1 추천질문 vs 자유입력

| 입력 유형 | 건수 | 비율 | 평균 토큰 | 평균 응답 길이 | 성공률 |
|-----------|------|------|----------|-------------|--------|
| **추천_종합분석** | 7,551 | 59.0% | 1,318 | 2,630자 | 99.97% |
| 자유_직접입력 | 3,398 | 26.6% | 501 | 1,002자 | 99.97% |
| 자유_종목명입력 | 1,391 | 10.9% | 634 | 1,302자 | 99.93% |
| 추천_애널리스트 | 323 | 2.5% | 607 | 1,290자 | 100% |
| 기타 추천질문 | 135 | 1.0% | ~700 | ~1,500자 | 100% |

> **핵심**: 전체 트래픽의 62.5%가 추천질문 (종합분석+애널리스트+기타). 이 영역은 성공률 100%에 가까움.  
> 문제는 **자유입력 37.5% (4,789건)** 에 집중.

### 2.2 자유입력 질문의 카테고리별 응답 품질

```
카테고리          | 건수  | 성공률  | 평균토큰 | 상태
─────────────────┼──────┼────────┼─────────┼──────────
뉴스 조회         |  799 | 98.5%  |   642   | ✅ 최고
주가 조회         | 1233 | 96.3%  |   645   | ✅ 우수
재무 분석         |  567 | 94.2%  |   425   | ✅ 양호
전망/예측         |  235 | 91.5%  |   637   | ✅ 양호
ETF/펀드          |  142 | 90.8%  |   423   | ✅ 양호
테마/섹터         |   62 | 87.1%  |   667   | ⚠️ 주의
단순 종목명       |  875 | 84.0%  |   906   | ⚠️ 주의
종목 비교         |   70 | 80.0%  |   530   | ⚠️ 개선 필요
기타              |  726 | 76.9%  |   496   | ⚠️ 개선 필요
방법 문의         |  129 | 74.4%  |   416   | 🟡 문제
용어 설명         |   67 | 68.7%  |   438   | 🟡 문제
애널리스트(자유)  |   10 | 50.0%  |   617   | 🔴 심각
매매 판단         |  126 | 25.4%  |   421   | 🔴 최악(Type A)
증권 업무         |   60 | 15.0%  |   329   | 🔴 최악(Type B)
```

### 2.3 핵심 인사이트

1. **상위 5개 카테고리 (뉴스/주가/재무/전망/ETF)가 자유입력의 62%**를 차지하며 성공률 90%+ → 이것이 "답변을 잘하는 질문들"
2. **하위 3개 카테고리 (매매판단/증권업무/용어설명)가 실패의 67%** 차지 → 가드레일 오탐 + 도메인 미지원
3. **단순 종목명 입력 (875건, 84% 성공)**: 16%가 실패하는 이유는 미등록 종목/오타

---

## 3. Golden Set 구축 전략

> **yeham**: "답변을 잘하는 질문들 리스트를 만들어둘 수 있음 → 이후 채팅들에 대한 자체 평가 기준이 될 수 있음"

### 3.1 Golden Set이란?

**"이 질문이 들어오면 이 수준의 답변이 나와야 한다"는 기준 Q&A 쌍 모음.**

```
Golden Set 구조:
├── 카테고리 (14개)
│   ├── 템플릿 (질문 형식)
│   │   ├── Q&A 쌍 (우수 답변 사례)  ← 기준선
│   │   ├── Q&A 쌍 (최소 허용 답변)  ← 하한선
│   │   └── Anti-pattern (이렇게 답하면 안 됨) ← 실패 사례
│   └── ...
└── ...
```

### 3.2 구축 방법론

**Phase 1: 자동 추출 (즉시 실행 가능)**

```sql
-- 카테고리별 "우수 답변" 자동 추출
-- 기준: output_tokens >= P75 (상위 25%), 실패 패턴 아님
SELECT category, user_input, llm_response, output_tokens
FROM classified_data
WHERE quality = 'OK'
  AND output_tokens >= PERCENTILE_CONT(output_tokens, 0.75) OVER (PARTITION BY category)
ORDER BY category, output_tokens DESC;
```

**Phase 2: LLM 평가 (1~2주)**

추출된 Q&A 쌍을 LLM에게 질문 수준 + 답변 품질을 동시 평가:

```
평가 요청 프롬프트:
다음 주식 관련 Q&A 쌍을 평가해주세요.

[질문 평가]
- 구체성 (0-3): 종목/지표가 명시되었는가
- 의도 명확성 (0-3): 원하는 정보가 분명한가
- 분석 깊이 (0-3): 단순 조회 vs 복합 분석
- 시간적 맥락 (0-2): 기간이 특정되었는가
- 비교 프레임 (0-2): 비교 대상이 있는가
→ 질문 Tier: S/A/B/C/D

[답변 평가]
- 정확성 (1-10): 제공된 정보가 정확한가
- 완결성 (1-10): 질문에 충분히 답했는가
- 유용성 (1-10): 투자 의사결정에 도움이 되는가
- 가독성 (1-10): 구조화/시각화가 적절한가
→ 답변 Grade: A/B/C/D/F
```

**Phase 3: 기준선 확정 (2~3주)**

| 카테고리 | Golden Q&A 수 | 기준선 답변 토큰 | 필수 포함 요소 |
|---------|-------------|--------------|-------------|
| 종합분석 | 20쌍 | 1200+ | 주가 테이블, 뉴스 요약, 재무 지표 |
| 주가조회 | 15쌍 | 400+ | 현재가, 등락률, 5일 차트 |
| 뉴스조회 | 15쌍 | 500+ | 뉴스 3건+, 영향도 분석 |
| 재무분석 | 15쌍 | 400+ | 매출/영업이익 테이블, YoY 비교 |
| 종목비교 | 10쌍 | 500+ | 비교 테이블, 차이점 요약 |
| ... | ... | ... | ... |

### 3.3 Golden Set 활용법

```
새 채팅 들어옴
  ↓
카테고리 분류 (기존 CategoryClassifierService 활용)
  ↓
해당 카테고리 Golden Set에서 유사 질문 검색
  ↓
├── 유사도 높은 Golden Q 있음
│   ├── 답변이 Golden A 수준 이상 → ✅ Pass
│   └── 답변이 Golden A 미달     → ⚠️ Alert + 개선 대상
└── 유사한 Golden Q 없음
    └── 새로운 질문 패턴 → Golden Set 편입 후보
```

---

## 4. 새 채팅 실시간 분류 파이프라인

> **yeham**: "새로운 채팅 들어왔을 때 여기에 편입시킬 것인지 판단 가능"

### 4.1 분류 의사결정 트리

```
user_input 수신
  │
  ├─ [1] 종목 인식 가능? ──────────────────────────────┐
  │   YES: 종목코드 추출                                │
  │   NO: → 비종목 질문 분기 ───────────┐               │
  │                                    │               │
  │   ├─ 증권업무 키워드?              │               │
  │   │   YES → 증권업무 카테고리       │               │
  │   ├─ 금융용어 질문?                │               │
  │   │   YES → 용어설명 카테고리       │               │
  │   └─ 기타 → 도메인 판단            │               │
  │       ├─ 금융 도메인 → 기타 카테고리│               │
  │       └─ 비금융 → OUT OF SCOPE    │               │
  │                                    │               │
  ├─ [2] 의도 분류 ←──────────────────┘               │
  │   ├─ 추천질문 매칭? → 추천질문 카테고리              │
  │   ├─ 매매판단 요청? → 매매판단 (가드레일 적용)       │
  │   ├─ 정보조회? → 주가/뉴스/재무/배당/전망 분류       │
  │   ├─ 비교요청? → 종목비교 카테고리                   │
  │   └─ 방법문의? → 방법문의 카테고리                   │
  │                                                     │
  ├─ [3] 질문 수준 스코어링 (§1.2의 5축)                │
  │   → Tier S/A/B/C/D 부여                             │
  │                                                     │
  ├─ [4] Golden Set 매칭                                │
  │   ├─ 기존 Golden Q 유사도 > 0.8 → 편입 (기존 카테고리)│
  │   ├─ 유사도 0.5~0.8 → 후보 (수동 리뷰 대기)         │
  │   └─ 유사도 < 0.5 → 신규 패턴 후보                  │
  │                                                     │
  └─ [5] 메타데이터 태깅 (BigQuery에 저장)
      {category, tier, golden_match, is_recommended_q}
```

### 4.2 기존 인프라 활용

코드베이스에 이미 있는 것:

| 기능 | 기존 모듈 | 상태 | 확장 필요 |
|------|----------|------|----------|
| 카테고리 분류 | `CategoryClassifierService` | ✅ 8개 범용 카테고리 | 14개 주식 특화 카테고리로 확장 |
| 감정 분석 | `SentimentAnalysisService` | ✅ 사용 가능 | 그대로 사용 |
| 품질 스코어링 | `BatchAnalysisResult` | ✅ 4점 척도 | 질문 수준 축 추가 |
| FAQ 클러스터링 | `FAQClusteringService` | ✅ 텍스트 정규화 + LLM 병합 | Golden Set 유사도에 활용 |
| 문제 채팅 탐지 | `ProblematicChatService` | ✅ 동적 규칙 엔진 | 규칙 추가로 확장 |

---

## 5. 유저 행동 데이터 분석

### 5.1 진입 패턴 (yeham 관찰 검증)

> "유저는 기본적으로 종목명과 같은 단순한 형식으로 채팅에 진입. 그 이후로는 추천질문만 사용."

**데이터 검증 (2월 기준):**

| 진입 유형 | 세션 수 | 비율 | 평균 대화수 | 단일턴 비율 |
|----------|---------|------|-----------|-----------|
| 추천질문 진입 | 5,327 | **84.1%** | 1.4 | 77.9% |
| 자유질문 진입 | 547 | 8.6% | 1.9 | 52.8% |
| 종목명 진입 | 458 | 7.2% | 1.9 | 52.0% |

**인사이트:**
- ✅ **확인됨**: 84%의 세션이 추천질문으로 시작
- ⚠️ **수정**: "종목명 진입"은 7.2%로 생각보다 적음 — 대부분 추천질문 UI에서 바로 "종합분석" 선택
- 📊 **종목명/자유질문 진입 시** 평균 1.9턴, 48%가 추가 대화 → 더 깊은 탐색 의지

**세션 흐름 실제 사례 (종목명 → 추천질문):**

| 1턴 (종목명) | 2턴 (추천질문) |
|-------------|---------------|
| "우리기술" | "원전 관련 뉴스가 우리기술에 미친 영향은?" |
| "스맥" | "스맥 최근 주가 변동 추세는 어때요?" |
| "휴림로봇" | "휴림로봇 관련 최신 뉴스 주요 내용 알려주세요" |
| "2차전지" | "2차전지 관련 국내 ETF는 어떤 게 있나요?" |

→ **유저 Journey**: 종목명 입력 → 시스템이 종목 인식 → 추천질문 제시 → 유저가 추천질문 선택

### 5.2 트래픽과 품질

> "채팅수가 많으면 답변을 제대로 하지 못하는 경우가 있음"

**일별 분석 (1/27 이후):**

| 일 트래픽 | 해당 일수 | 평균 실패율 | 상관관계 |
|----------|----------|-----------|---------|
| ~200건 미만 | 5일 | 4.1% | 기준선 |
| 200~500건 | 7일 | 5.2% | 약한 상승 |
| 500~800건 | 8일 | 4.7% | 유의미하지 않음 |
| 800건 이상 | 4일 | 5.0% | 유의미하지 않음 |

→ **결론**: 트래픽 자체보다는 **자유입력 비율**이 실패율과 더 상관. 트래픽이 높은 날은 추천질문 비중도 높아서 상쇄됨.

### 5.3 같은 형식 + 다른 종목 = 다른 질문?

> **yeham**: "질문 형식이 동일해도 종목을 변경해서 넣는 경우 → 다른 질문으로 보기"

**데이터 분석:**

Top 종목별 "종합분석" 요청 빈도:

| 종목 | 동일 형식 건수 | 평균 응답 길이 | 평균 토큰 |
|------|-------------|-------------|----------|
| 삼성전자 | 179 | 3,249자 | 1,576 |
| 두산에너빌리티 | 102 | 2,884자 | 1,437 |
| 한온시스템 | 78 | 2,911자 | 1,464 |
| 휴림로봇 | 78 | 2,444자 | 1,219 |
| SK하이닉스 | 76 | 3,164자 | 1,551 |

**제안하는 구분 체계:**

```
질문 = 템플릿 × 인스턴스

템플릿: "{종목명}({종목코드})를 종합적으로 분석해줘"
인스턴스: "삼성전자(005930)를 종합적으로 분석해줘"

→ 같은 템플릿이지만 다른 인스턴스 = "다른 질문"으로 카운트
→ 품질 평가 시에는 템플릿 단위로 집계 (종목별 편차 확인)
```

**이유**:
- 같은 템플릿이어도 종목에 따라 **데이터 가용성이 다름** (삼성전자 3,249자 vs 휴림로봇 2,444자)
- 종목별로 **뉴스/재무 데이터의 양과 질이 다름**
- 따라서 동일 템플릿이어도 **종목별 응답 품질 편차를 모니터링**해야 함

---

## 6. 실행 계획: LLM 카테고라이징 → 인사이트 파이프라인

> **yeham**: "질문들 모조리 긁어서 LLM한테 카테고라이징 맡기기. 카테고라이징 이후, 해당 카테고리에 있는 질문과 답변 쌍들 그대로 LLM한테 전달해서 insight 뽑아내기"

### 6.1 파이프라인 설계

```
[Stage 1] 데이터 추출
  BigQuery → 자유입력 질문 4,789건 추출
  (추천질문 제외 — 이미 품질 검증됨)
  │
  ▼
[Stage 2] LLM 카테고라이징 (배치)
  14개 카테고리 × 질문수준 Tier 동시 부여
  배치 사이즈: 50개/회 × ~96회 = ~4,800건
  예상 비용: ~$15-20 (GPT-4o 기준)
  │
  ▼
[Stage 3] 카테고리별 Q&A 쌍 묶기
  각 카테고리에서:
  - 상위 30% (Good 답변) 추출
  - 하위 10% (Bad 답변) 추출
  │
  ▼
[Stage 4] LLM 인사이트 추출 (카테고리별)
  프롬프트 예시:
  "다음은 [주가조회] 카테고리의 Q&A 쌍 50개입니다.
   - 잘 답변된 사례 30개
   - 못 답변된 사례 20개
   
   분석해주세요:
   1. 잘 답변된 질문들의 공통 특징
   2. 못 답변된 질문들의 공통 특징
   3. 같은 카테고리인데 품질 차이가 나는 원인
   4. 답변 개선을 위한 구체적 제안
   5. 이 카테고리에서 Golden Q&A 후보 5개 선정"
  │
  ▼
[Stage 5] 종합 보고서 + Golden Set 초안
```

### 6.2 LLM 카테고라이징 프롬프트 (구체적)

```
당신은 증권사 AI 챗봇의 질문 분류 전문가입니다.

다음 질문들을 분류해주세요. 각 질문에 대해:

1. category (하나만):
   - stock_price: 주가/시세/현재가/등락 조회
   - news: 뉴스/동향/이슈 조회
   - financial: 재무제표/실적/매출/영업이익
   - analyst: 목표주가/컨센서스/리포트
   - comparison: 종목 비교/유사 종목
   - etf_fund: ETF/펀드/인덱스
   - sector_theme: 테마/섹터/업종/관련주
   - trading: 매매/매수/매도 판단 요청
   - forecast: 전망/예측/향후
   - brokerage: 수수료/계좌/이체/거래시간
   - howto: 방법/절차 문의
   - terminology: 용어/개념 설명
   - simple_name: 종목명만 입력
   - other: 위 어디에도 해당 안 됨

2. tier (S/A/B/C/D):
   - S: 종목+지표+기간+비교 모두 구체적
   - A: 종목+정보유형 명시
   - B: 대상은 있으나 요청이 모호
   - C: 단어 수준 입력
   - D: 의미 파악 불가

3. answerable (yes/no/partial):
   - yes: 우리 시스템으로 완전 답변 가능
   - partial: 일부만 답변 가능
   - no: 답변 불가 (도메인 외 or 투자추천)

질문 목록:
{questions}
```

### 6.3 비용/일정 추정

| 단계 | 소요 시간 | 비용 | 산출물 |
|------|----------|------|--------|
| Stage 1: 데이터 추출 | 30분 | $0 | CSV 4,789건 |
| Stage 2: LLM 카테고라이징 | 2~3시간 | ~$20 | 분류 결과 |
| Stage 3: Q&A 묶기 | 1시간 | $0 | 카테고리별 Q&A 셋 |
| Stage 4: 인사이트 추출 | 3~4시간 | ~$15 | 14개 카테고리 인사이트 |
| Stage 5: 보고서 + Golden Set | 1일 | $0 | 최종 보고서 |
| **합계** | **~2일** | **~$35** | **Golden Set 초안 + 인사이트** |

---

## 7. 종합 권장사항

### 즉시 (이번 주)

1. **Stage 1~2 실행**: 자유입력 4,789건 LLM 카테고라이징
2. **기존 `CategoryClassifierService` 키워드 확장**: 현재 8개 범용 → 14개 주식 특화로
3. **Golden Set 자동 추출 쿼리 작성**: 카테고리별 상위 답변 자동 수집

### 단기 (2주)

4. **Stage 3~5 실행**: 카테고리별 인사이트 + Golden Set 초안
5. **질문 수준 스코어링 로직 구현**: 5축 평가 → Tier 자동 부여
6. **BigQuery에 메타데이터 칼럼 추가**: `question_category`, `question_tier`, `is_golden`

### 중기 (1개월)

7. **실시간 분류 파이프라인 배포**: 새 채팅 → 자동 카테고리/Tier 태깅
8. **Golden Set 기반 품질 모니터링**: 카테고리별 응답 품질 대시보드
9. **주간 리포트 자동화**: 카테고리별 실패율/신규 패턴/Golden Set 편입 후보

---

*보고서 생성: 2026-02-19 | 데이터 기준: BigQuery view_ola_monitoring*
